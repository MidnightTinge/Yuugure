// dbdiagram.io schema
// $ npm i -g @dbml/cli
// $ dbml2sql --postgres --out-file "SCHEMA.sql" yuugure.dbml
//
// We use the resulting SCHEMA.sql to seed docker containers.
//

table account {
  id           int         [pk, increment]
  username     varchar(32) [not null]
  email        text        [not null]
  password     varchar(60) [not null]
  state        bigint      [not null, default: 0]
  registered   timestamptz [not null, default: `now()`]

  indexes {
    `lower(username)`     [unique]
  }
}

table sessions {
  id      int         [pk, increment]
  token   varchar(32) [not null]
  account int         [not null, ref:> account.id]
  created timestamptz [not null, default: `now()`]
  expires timestamptz [not null]

  indexes {
    token
  }
}

table media { // used as a cache of sorts for seen media. if duplicate uploads are enabled in config, we'll hit this table first to avoid caclulcating extra hashes
  id     int          [pk, increment]
  sha256 varchar(64)  [not null] // our own internal hash because why do people still use md5?
  md5    varchar(32)  [not null] // necessary for compatible searches with other services that still md5 hash files
  phash  varchar(256) [not null] // will be used in the future for hamming distance stuff (similar image detection)
  mime   text         [not null] // used for rendering (e.g. video detection)

  indexes {
    sha256
    md5
    (sha256, md5) [name: "both_hash_idx"]
    phash // we'll index phash for easier searching later
  }
}

table media_meta { // meta is attached as a second step and not present on initial upload
  id             int     [pk, increment]
  media          int     [not null, unique, ref:> media.id]
  width          int     [not null]
  height         int     [not null]
  video          boolean [not null]
  video_duration real    [not null, default: `0`]
  has_audio      boolean [not null, default: `false`]
  filesize       bigint  [not null]

  indexes {
    media [unique, name: "media_meta_media_unique"]
    video
    has_audio
    filesize
  }
}

table upload { // used for individual uploads since media serves as an upload cache based on the sha. if dupes are allowed via config, this is necessary to differentiate between user uploads
  id          int         [pk, increment]
  media       int         [not null, ref:> media.id]
  parent      int         [ref:> media.id]
  owner       int         [not null, ref:> account.id]
  upload_date timestamptz [not null, default: `now()`]
  state       bigint      [not null, default: 0] // state is a bitfield that denotes whether something is deleted, awaiting moderation, etc. i'm doing it this way to avoid another "media_state" table or adding 15 more columns here.

  indexes {
    media
    owner
    parent // for moderation aggregation
    upload_date
  }
}

table processing_queue { // processing is handled by slave processes so we need a master source to hand out jobs
  id         int         [pk, increment]
  upload     int         [ref:> upload.id]
  queued_at  timestamptz [not null, default: `now()`]
  dequeued   boolean     [not null, default: `false`]
  errored    boolean     [not null, default: `false`]
  error_text text
  finished   boolean     [not null, default: `false`]

  indexes {
    queued_at
    upload
    dequeued
    errored
    finished
  }
}

table audits {
  id          int         [pk, increment]
  account     int         [not null, ref:> account.id]
  target_type text        [not null]
  target_id   text        [not null]
  action      text        [not null]
  tstamp      timestamptz [not null, default: `now()`]
  details     text        [not null, default: ""]

  indexes {
    account
    (target_type, target_id)
    action
    (account, action)
    (account, action, target_type)
    tstamp
  }
}

Table report {
  id          int         [pk, increment]
  active      boolean     [not null, default: `true`]
  account     int         [ref:> account.id]
  timestamp   timestamptz [not null, default: `now()`]
  claimed     boolean     [not null, default: `false`]
  claimed_by  int         [ref:> account.id]
  target_type text        [not null, default: "upload"]
  target_id   int         [not null]
  content     text        [not null]

  indexes {
    active
    account
    claimed
    (target_type, target_id)
    (target_type, target_id, active)
  }
}

table comment {
  id               int         [pk, increment]
  parent           int         [ref:> comment.id] // for replies
  account          int         [not null, ref:> account.id]
  active           boolean     [not null, default: `true`]
  timestamp        timestamptz [not null, default: `now()`]
  target_type      text        [not null, default: "upload"] // 'account'|'upload'|'tag' etc
  target_id        int         [not null]
  content_raw      text        [not null]
  content_rendered text        [not null]

  indexes {
    target_type // future moderation expansion
    (target_type, target_id)
    parent
  }
}

table panic_connection {
  addr      bytea       [not null]
  hits      int         [not null, default: 0]
  timestamp timestamptz [not null, default: `now()`]
  expires   timestamptz [not null, default: `now()`]

  indexes {
    addr [unique]
  }
}

table tag {
  id         int  [pk, increment]
  parent     int  [ref:> tag.id]
  category   text [not null] // enables us to do something like `filesize:tiny` in an aggregatable way
  name       text [not null]
  assoc_type text // associations are to other objects allowing us to have an `artist:name` associated with an `artist` table.
  assoc_id   int

  indexes {
    (`lower(category)`, `lower(name)`) [unique]
    `lower(category)`
    `lower(name)`
    (assoc_type, assoc_id)
    assoc_type // for future aggregation
  }
}

table upload_tags {
  upload int [not null, ref:> upload.id]
  tag int [not null, ref:> tag.id]

  indexes {
    (upload, tag) [unique]
  }
}

table upload_bookmark {
  active    boolean     [not null, default: `false`]
  timestamp timestamptz [not null, default: `now()`]
  public    boolean     [not null]
  upload    int         [not null, ref:> upload.id]
  account   int         [not null, ref:> account.id]

  indexes {
    (upload, account) [pk]
    timestamp
    upload
    account
    (upload, account) [unique, name: "bookmark_account_upload_pair_unique"]
    (account, active)
    (upload, active)
    (upload, active, public)
    (account, active, public)
  }
}

table upload_vote {
  active  boolean [not null, default: `false`]
  is_up   boolean [not null, default: `false`]
  upload  int     [not null, ref:> upload.id]
  account int     [not null, ref:> account.id]

  indexes {
    (upload, account) [pk]
    upload
    account
    active
    (upload, account) [unique, name: "vote_account_upload_pair_unique"]
    (account, active)
    (upload, active)
    (upload, active, is_up)
  }
}
